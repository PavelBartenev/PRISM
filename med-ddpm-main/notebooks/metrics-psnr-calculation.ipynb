{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ead52a-2849-4294-8a67-de9147c7fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('/workspace/MRI-inpainting-project')\n",
    "\n",
    "from data_scripts.datasets import PathologicalMRIDataset, HealthyMRIDataset, TrainPatchesDataset\n",
    "from data_scripts.visualization_utils import ImageSliceViewer3D\n",
    "\n",
    "%autoreload 2\n",
    "from dataset import NiftiImageGenerator, NiftiPairImageGenerator, TrainFCDDataset, HealthyFCDDataset, TrainFCDPatchesDataset\n",
    "from torchvision.transforms import RandomCrop, Compose, ToPILImage, Resize, ToTensor, Lambda\n",
    "import torch\n",
    "from diffusion_model.unet import create_model\n",
    "from diffusion_model.trainer import GaussianDiffusion\n",
    "\n",
    "from dataset import reconstruct_patch\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio \n",
    "from skimage.metrics import structural_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d88d87da-803d-4fad-8f5a-998724bbe38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint_train_patch(medddpm_dataset, orig_dataset, model, sample_id):\n",
    "    sample = medddpm_dataset[sample_id]\n",
    "    orig_patch, orig_fcd_mask = orig_dataset[sample_id]['patch'], orig_patches_dataset[sample_id]['mask']\n",
    "    gen_patch = model.sample(batch_size=1, condition_tensors=sample['input'].unsqueeze(0).cuda('cuda:2'))\n",
    "    gen_patch = gen_patch.cpu().numpy().squeeze()\n",
    "    recon_patch = reconstruct_patch(orig_patch, gen_patch, orig_fcd_mask)\n",
    "\n",
    "    return recon_patch, orig_patch, orig_fcd_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1976f2b4-5fa6-44eb-a019-5e0f088c8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=40\n",
    "depth_size=40\n",
    "\n",
    "transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "    Lambda(lambda t: t.unsqueeze(0)),\n",
    "    Lambda(lambda t: t.transpose(3, 1)),\n",
    "])\n",
    "\n",
    "input_transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "    Lambda(lambda t: t.permute(3, 0, 1, 2)),\n",
    "    Lambda(lambda t: t.transpose(3, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0597698f-d2c6-4b25-b1ff-5cb9da2c6693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = '../scripts/results/train_fcd_inpainting_data_l1_masked_patches_split0_500_000/model-2.pt'\n",
    "\n",
    "channel_mult = \"1,2,4,4\"\n",
    "\n",
    "with torch.cuda.device('cuda:2'):\n",
    "    model = create_model(input_size, num_channels=64, num_res_blocks=1, in_channels=3, out_channels=1, channel_mult=channel_mult).cuda()\n",
    "    \n",
    "    diffusion = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size = input_size,\n",
    "        depth_size = depth_size,\n",
    "        timesteps = 250,   # number of steps\n",
    "        loss_type = 'l1_masked', \n",
    "        with_condition=True,\n",
    "    ).cuda()\n",
    "    \n",
    "    diffusion.load_state_dict(torch.load(ckpt_path, map_location='cuda:2')['ema'])\n",
    "    print(\"Model Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5153121c-1209-4949-ae7f-714484d70dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches_dataset = TrainFCDPatchesDataset('../../data/train_patches_v3', input_size, depth_size, \n",
    "                                               mask_transform=input_transform, target_transform=transform, \n",
    "                                               splits_filename='stratified_8_cv_filtered_2.npy', split_id=0, \n",
    "                                               train=False)\n",
    "orig_patches_dataset = TrainPatchesDataset('../../data/train_patches_v3', \n",
    "                                           splits_filename='stratified_8_cv_filtered_2.npy', split_id=0, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1d73fda-c505-454c-89e9-b8518811f64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 12.92it/s]\n"
     ]
    }
   ],
   "source": [
    "recon_patch, orig_patch, orig_fcd_mask = inpaint_train_patch(train_patches_dataset, orig_patches_dataset,\n",
    "                                                             diffusion, sample_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3b5f405-9443-4b11-abf1-c7634a22109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fcd = recon_patch[orig_fcd_mask > 0.5]\n",
    "fcd = orig_patch[orig_fcd_mask > 0.5]\n",
    "\n",
    "psnr = peak_signal_noise_ratio(fcd, gen_fcd, data_range = fcd.max() - fcd.min())\n",
    "ssim = structural_similarity(fcd, gen_fcd, data_range = fcd.max() - fcd.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a044f807-2f85-4299-8f2b-2a4adea78276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:18<00:00, 13.74it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:18<00:00, 13.65it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:18<00:00, 13.52it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 13.14it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 12.79it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 12.57it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.50it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.44it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.49it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.42it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.43it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.40it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.38it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.49it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.41it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.38it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.43it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.42it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.37it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.38it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.45it/s]\n"
     ]
    }
   ],
   "source": [
    "psnr_list = []\n",
    "ssim_list = []\n",
    "\n",
    "for sample_id in range(len(orig_patches_dataset)):\n",
    "    recon_patch, orig_patch, orig_fcd_mask = inpaint_train_patch(train_patches_dataset, orig_patches_dataset,\n",
    "                                                                 diffusion, sample_id=sample_id)\n",
    "    gen_fcd = recon_patch[orig_fcd_mask > 0.5]\n",
    "    fcd = orig_patch[orig_fcd_mask > 0.5]\n",
    "    \n",
    "    psnr = peak_signal_noise_ratio(fcd, gen_fcd, data_range = fcd.max() - fcd.min())\n",
    "    ssim = structural_similarity(fcd, gen_fcd, data_range = fcd.max() - fcd.min())\n",
    "\n",
    "    psnr_list.append(psnr)\n",
    "    ssim_list.append(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61d191-3fe7-4604-9bdc-809867fac95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../stats/psnr_3ddiffusion_split0.npy', psnr_list)\n",
    "np.save('../stats/ssim_3ddiffusion_split0.npy', ssim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5b4ee-57a3-4828-bee9-671cc6c8af82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion3d",
   "language": "python",
   "name": "diffusion3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
