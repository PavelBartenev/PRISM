{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ead52a-2849-4294-8a67-de9147c7fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('/workspace/MRI-inpainting-project')\n",
    "\n",
    "from data_scripts.datasets import PathologicalMRIDataset, HealthyMRIDataset, TrainPatchesDataset\n",
    "from data_scripts.visualization_utils import ImageSliceViewer3D\n",
    "\n",
    "%autoreload 2\n",
    "from dataset import NiftiImageGenerator, NiftiPairImageGenerator, TrainFCDDataset, HealthyFCDDataset, TrainFCDPatchesDataset\n",
    "from torchvision.transforms import RandomCrop, Compose, ToPILImage, Resize, ToTensor, Lambda\n",
    "import torch\n",
    "from diffusion_model.unet import create_model\n",
    "from diffusion_model.trainer import GaussianDiffusion\n",
    "\n",
    "from dataset import reconstruct_patch\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio \n",
    "from skimage.metrics import structural_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d88d87da-803d-4fad-8f5a-998724bbe38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint_train_patch(medddpm_dataset, orig_dataset, model, sample_id):\n",
    "    sample = medddpm_dataset[sample_id]\n",
    "    orig_patch, orig_fcd_mask = orig_dataset[sample_id]['patch'], orig_patches_dataset[sample_id]['mask']\n",
    "    gen_patch = model.sample(batch_size=1, condition_tensors=sample['input'].unsqueeze(0).cuda('cuda:2'))\n",
    "    gen_patch = gen_patch.cpu().numpy().squeeze()\n",
    "    recon_patch = reconstruct_patch(orig_patch, gen_patch, orig_fcd_mask)\n",
    "\n",
    "    return recon_patch, orig_patch, orig_fcd_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1976f2b4-5fa6-44eb-a019-5e0f088c8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=40\n",
    "depth_size=40\n",
    "\n",
    "transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "    Lambda(lambda t: t.unsqueeze(0)),\n",
    "    Lambda(lambda t: t.transpose(3, 1)),\n",
    "])\n",
    "\n",
    "input_transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "    Lambda(lambda t: t.permute(3, 0, 1, 2)),\n",
    "    Lambda(lambda t: t.transpose(3, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0597698f-d2c6-4b25-b1ff-5cb9da2c6693",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../scripts/results/train_fcd_inpainting_data_l1_masked_patches_split1_500_000/model-2.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m channel_mult \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1,2,4,4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(input_size, num_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_res_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, channel_mult\u001b[38;5;241m=\u001b[39mchannel_mult)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      8\u001b[0m     diffusion \u001b[38;5;241m=\u001b[39m GaussianDiffusion(\n\u001b[1;32m      9\u001b[0m         model,\n\u001b[1;32m     10\u001b[0m         image_size \u001b[38;5;241m=\u001b[39m input_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         with_condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     )\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/miniconda3/envs/diffusion3d/lib/python3.10/site-packages/torch/cuda/__init__.py:287\u001b[0m, in \u001b[0;36mdevice.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_idx \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx:\n\u001b[1;32m    289\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx)\n",
      "File \u001b[0;32m~/miniconda3/envs/diffusion3d/lib/python3.10/site-packages/torch/cuda/__init__.py:552\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    551\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/miniconda3/envs/diffusion3d/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "ckpt_path = '../scripts/results/train_fcd_inpainting_data_l1_masked_patches_split1_500_000/model-2.pt'\n",
    "\n",
    "channel_mult = \"1,2,4,4\"\n",
    "\n",
    "with torch.cuda.device('cuda:2'):\n",
    "    model = create_model(input_size, num_channels=64, num_res_blocks=1, in_channels=3, out_channels=1, channel_mult=channel_mult).cuda()\n",
    "    \n",
    "    diffusion = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size = input_size,\n",
    "        depth_size = depth_size,\n",
    "        timesteps = 250,   # number of steps\n",
    "        loss_type = 'l1_masked', \n",
    "        with_condition=True,\n",
    "    ).cuda()\n",
    "    \n",
    "    diffusion.load_state_dict(torch.load(ckpt_path, map_location='cuda:2')['ema'])\n",
    "    print(\"Model Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5153121c-1209-4949-ae7f-714484d70dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches_dataset = TrainFCDPatchesDataset('../../data/train_patches_v3', input_size, depth_size, \n",
    "                                               mask_transform=input_transform, target_transform=transform, \n",
    "                                               splits_filename='stratified_8_cv_filtered_2.npy', split_id=0, \n",
    "                                               train=False)\n",
    "orig_patches_dataset = TrainPatchesDataset('../../data/train_patches_v3', \n",
    "                                           splits_filename='stratified_8_cv_filtered_2.npy', split_id=0, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1d73fda-c505-454c-89e9-b8518811f64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 12.92it/s]\n"
     ]
    }
   ],
   "source": [
    "recon_patch, orig_patch, orig_fcd_mask = inpaint_train_patch(train_patches_dataset, orig_patches_dataset,\n",
    "                                                             diffusion, sample_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3b5f405-9443-4b11-abf1-c7634a22109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fcd = recon_patch[orig_fcd_mask > 0.5]\n",
    "fcd = orig_patch[orig_fcd_mask > 0.5]\n",
    "\n",
    "psnr = peak_signal_noise_ratio(fcd, gen_fcd, data_range = fcd.max() - fcd.min())\n",
    "ssim = structural_similarity(fcd, gen_fcd, data_range = fcd.max() - fcd.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a044f807-2f85-4299-8f2b-2a4adea78276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:18<00:00, 13.74it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:18<00:00, 13.65it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:18<00:00, 13.52it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 13.14it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 12.79it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:19<00:00, 12.57it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.50it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.44it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.49it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.42it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.43it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.40it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.38it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.49it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.41it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.38it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.43it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.42it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.37it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.38it/s]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:20<00:00, 12.45it/s]\n"
     ]
    }
   ],
   "source": [
    "psnr_list = []\n",
    "ssim_list = []\n",
    "\n",
    "for sample_id in range(len(orig_patches_dataset)):\n",
    "    recon_patch, orig_patch, orig_fcd_mask = inpaint_train_patch(train_patches_dataset, orig_patches_dataset,\n",
    "                                                                 diffusion, sample_id=sample_id)\n",
    "    gen_fcd = recon_patch[orig_fcd_mask > 0.5]\n",
    "    fcd = orig_patch[orig_fcd_mask > 0.5]\n",
    "    \n",
    "    psnr = peak_signal_noise_ratio(fcd, gen_fcd, data_range = fcd.max() - fcd.min())\n",
    "    ssim = structural_similarity(fcd, gen_fcd, data_range = fcd.max() - fcd.min())\n",
    "\n",
    "    psnr_list.append(psnr)\n",
    "    ssim_list.append(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61d191-3fe7-4604-9bdc-809867fac95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../stats/psnr_3ddiffusion_split0.npy', psnr_list)\n",
    "np.save('../stats/ssim_3ddiffusion_split0.npy', ssim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501ca0d6-05b2-4c1a-9897-85785ee7bc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.322131160799639"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../stats/psnr_3ddiffusion_split0.npy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9beb947-7fb6-4968-a2cf-ac5af579a612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3858638821655331"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../stats/ssim_3ddiffusion_split0.npy').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion3d",
   "language": "python",
   "name": "diffusion3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
